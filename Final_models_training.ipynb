{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "bf7d6ddf-e9b4-4551-998b-0f326b638baa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0\n",
    "%reload_ext autoreload\n",
    "!pip install -U imbalanced-learn\n",
    "import threadpoolctl\n",
    "threadpoolctl.threadpool_info()\n",
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "63c666f7-5442-4a65-a859-8c42a1812da5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install xgboost\n",
    "%pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1524f5c-4d5d-4744-8293-e65e40824146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import preprocessing\n",
    "from preprocessing import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, matthews_corrcoef, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dacdee1-22aa-4ccf-b09a-609fa43f3491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"emi_prediction_dataset.csv\", low_memory=False)\n",
    "pre=quality_check(data, Prediction=False)\n",
    "n_data = pre.final_processsing().emi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a1cc981-a28c-48c3-a339-8f9637928d34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_cols=['emi_eligibility', 'max_monthly_emi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6981e3d-3727-4096-9eaa-7684deb6af19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_data[\"emi_eligibility\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ccedf2-fbb0-4842-a7dc-cd470e1152d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_data[\"Savings\"] = n_data[\"bank_balance\"] + n_data[\"emergency_fund\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50aa96df-c4be-458d-9f8c-776998aca8b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "dc8d9433-3c0d-4997-8023-a2f252bd380e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def data_prepare(data, datatype=\"type1\", target_type=None):\n",
    "    final_columns_v1 = [\n",
    "    'gender', 'marital_status', 'education', 'monthly_salary',\n",
    "       'employment_type', 'years_of_employment', 'company_type', 'house_type',\n",
    "       'monthly_rent', 'family_size', 'dependents', 'school_fees',\n",
    "       'college_fees', 'travel_expenses', 'groceries_utilities',\n",
    "       'other_monthly_expenses', 'existing_loans', 'current_emi_amount',\n",
    "       'credit_score', 'bank_balance', 'emergency_fund', 'emi_scenario',\n",
    "       'requested_amount', 'requested_tenure']\n",
    "    final_columns_v2=[\n",
    "     'gender', 'marital_status', 'education', 'monthly_salary',\n",
    "       'employment_type', 'years_of_employment', 'company_type', 'house_type',\n",
    "       'monthly_rent', 'family_size', 'dependents',  'existing_loans', 'credit_score', 'emi_scenario',\n",
    "       'requested_amount', 'requested_tenure', 'Total_Fixed_expenses',\n",
    "       'Total_Other_expenses','Savings']\n",
    "    if datatype==\"type1\":\n",
    "        if target_type==None:\n",
    "            final_data=data[final_columns_v1]\n",
    "        elif target_type==\"regression\":\n",
    "            final_data=data[final_columns_v1]\n",
    "            final_data['max_monthly_emi']=data[\"max_monthly_emi\"]\n",
    "        elif target_type==\"classification\":\n",
    "            final_data=data[final_columns_v1]\n",
    "            final_data['emi_eligibility']=data[\"emi_eligibility\"]\n",
    "        else:\n",
    "            print(\"Please enter correct target type\")\n",
    "    elif datatype==\"type2\":\n",
    "        if target_type==None:\n",
    "            final_data=data[final_columns_v2]\n",
    "        elif target_type==\"regression\":\n",
    "            final_data=data[final_columns_v2]\n",
    "            final_data['max_monthly_emi']=data[\"max_monthly_emi\"]\n",
    "        elif target_type==\"classification\":\n",
    "            final_data=data[final_columns_v2]\n",
    "            final_data['emi_eligibility']=data[\"emi_eligibility\"]\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "593d09e5-5227-4c6a-ad61-a643e7f3a2df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "def data_split(x_data,y_data, rebalance = False):\n",
    "    X=x_data\n",
    "    y=y_data\n",
    "    if rebalance==True:\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X, y = sm.fit_resample(X, y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e66a4f27-e923-40f7-b330-6bc7a70dda49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcff4903-1c14-4793-bb27-62d6d955e745",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"assets/v1_scaler.pkl\", \"rb\") as f:\n",
    "    v1_scaler = pickle.load(f)\n",
    "with open(\"assets/v2_scaler.pkl\", \"rb\") as f:\n",
    "    v2_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c01bea5b-5972-4039-800c-5ddf3e7f3195",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_type1_c=data_prepare(n_data, target_type=\"classification\", datatype=\"type1\")\n",
    "data_type2_c=data_prepare(n_data, target_type=\"classification\", datatype=\"type2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d3095d2-ad86-4eb0-88ed-31068fbfda83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_type1_r=data_prepare(n_data, target_type=\"regression\", datatype=\"type1\")\n",
    "data_type2_r=data_prepare(n_data, target_type=\"regression\", datatype=\"type2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd82dc17-6c54-4d13-882f-9002ed7ed3c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_dtype_1=data_type1_c.drop(\"emi_eligibility\", axis=1)\n",
    "x_dtype_2=data_type2_c.drop(\"emi_eligibility\", axis=1)\n",
    "y_c=data_type2_c[\"emi_eligibility\"]\n",
    "y_r=data_type2_r[\"max_monthly_emi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b26417d3-8067-41ea-8ffa-e74347a91af5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3ee5f988-6045-42ba-9456-36dc740a786d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    median_absolute_error\n",
    ")\n",
    "\n",
    "def log_regression_metrics(y_true, y_pred):\n",
    "    \"\"\"Logs standard regression metrics to MLflow.\"\"\"\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    evs = explained_variance_score(y_true, y_pred)\n",
    "    medae = median_absolute_error(y_true, y_pred)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"mape(%)\": mape,\n",
    "        \"r2\": r2,\n",
    "        \"explained_variance\": evs,\n",
    "        \"median_ae\": medae\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0f7dab57-6c53-49ea-825e-d6998afea81d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, matthews_corrcoef, precision_recall_fscore_support\n",
    "def logging(y_test, pred, model_name=\"model\"):\n",
    "    # --- 1Ô∏è‚É£ Core Metrics ---\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, pred))\n",
    "    mlflow.log_metric(\"f1_score_weighted\", f1_score(y_test, pred, average='weighted'))\n",
    "    mlflow.log_metric(\"recall_weighted\", recall_score(y_test, pred, average='weighted'))\n",
    "    mlflow.log_metric(\"precision_weighted\", precision_score(y_test, pred, average='weighted'))\n",
    "\n",
    "    balanced_acc = balanced_accuracy_score(y_test, pred)\n",
    "    kappa = cohen_kappa_score(y_test, pred)\n",
    "    mcc = matthews_corrcoef(y_test, pred)\n",
    "\n",
    "    mlflow.log_metric(\"balanced_accuracy\", balanced_acc)\n",
    "    mlflow.log_metric(\"cohen_kappa\", kappa)\n",
    "    mlflow.log_metric(\"mcc\", mcc)\n",
    "\n",
    "    # --- 2Ô∏è‚É£ Confusion Matrix ---\n",
    "    cm = confusion_matrix(y_test, pred, labels=np.unique(y_test))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_test))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp.plot(cmap='Blues', ax=ax, colorbar=False)\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "\n",
    "    mlflow.log_figure(fig, f\"{model_name}_confusion_matrix.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # --- 3Ô∏è‚É£ Per-Class Metrics ---\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, pred, average=None, labels=np.unique(y_test)\n",
    "    )\n",
    "\n",
    "    for i, label in enumerate(np.unique(y_test)):\n",
    "        mlflow.log_metric(f\"precision_class_{label}\", prec[i])\n",
    "        mlflow.log_metric(f\"recall_class_{label}\", rec[i])\n",
    "        mlflow.log_metric(f\"f1_class_{label}\", f1[i])\n",
    "\n",
    "    # --- 4Ô∏è‚É£ Log CM as artifact ---\n",
    "    #mlflow.log_artifact(figure=f\"{model_name}_confusion_matrix.png\")\n",
    "\n",
    "    print(f\"‚úÖ Logged metrics and confusion matrix for {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe10b014-815b-4248-916b-29add5d33479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiment_name= \"/Workspace/Users/sushantkashikar1@gmail.com/mlflow/Final_model_Training\"\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except:\n",
    "    print(\"Experiment_already Exists\")\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4219739-72fd-489e-80f6-c71248de5d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4083e16a-628a-406f-8693-4e085aa2c6b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "419f2a28-32ed-46b2-9a82-00e71f805036",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "# or from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_dtype_1, y_r, test_size=0.2, random_state=42)\n",
    "run_name=\"lightgbm_regressor\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    best_params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 50,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.8,                # same as bagging_fraction\n",
    "    \"colsample_bytree\": 0.8,         # same as feature_fraction\n",
    "    \"reg_alpha\": 0.1,                # L1 regularization\n",
    "    \"reg_lambda\": 0.2,               # L2 regularization\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1}\n",
    "    model = LGBMRegressor(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    log_regression_metrics(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"LGBMRegressor\",signature= infer_signature(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fb4da28-e4be-4372-bf3d-48cb7b1125d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "# or from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_dtype_2, y_r, test_size=0.2, random_state=42)\n",
    "run_name=\"lightgbm_regressor_dtype2\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    best_params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 50,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.8,                # same as bagging_fraction\n",
    "    \"colsample_bytree\": 0.8,         # same as feature_fraction\n",
    "    \"reg_alpha\": 0.1,                # L1 regularization\n",
    "    \"reg_lambda\": 0.2,               # L2 regularization\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1}\n",
    "    model = LGBMRegressor(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    log_regression_metrics(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"LGBMRegressor\",signature= infer_signature(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e94c2038-e967-46ee-accf-edf922d9a22c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_dtype_1, y_r, test_size=0.2, random_state=42)\n",
    "run_name = \"xgboost_regressor_dtype1\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    best_params = {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"max_depth\": 8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"reg_alpha\": 0.1,\n",
    "        \"reg_lambda\": 0.2,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "    model = XGBRegressor(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    log_regression_metrics(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"XGBRegressor\", signature= infer_signature(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eed8e67-8871-41f4-8909-51aad6ad5cae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_dtype_2, y_r, test_size=0.2, random_state=42)\n",
    "run_name = \"xgboost_regressor_dtype2\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    best_params = {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"max_depth\": 8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"reg_alpha\": 0.1,\n",
    "        \"reg_lambda\": 0.2,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "    model = XGBRegressor(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mlflow.log_params(best_params)\n",
    "    log_regression_metrics(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"XGBRegressor\", signature= infer_signature(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa588e31-92c6-4e2f-97ad-a382caaa9dc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_dtype_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23e2ff82-44d2-4d26-aaed-f0e61c48623d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_dtype_2, y_r, test_size=0.2, random_state=42)\n",
    "best_params = {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"max_depth\": 8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"reg_alpha\": 0.1,\n",
    "        \"reg_lambda\": 0.2,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "regressor_model = XGBRegressor(**best_params)\n",
    "regressor_model.fit(X_train, y_train)\n",
    "y_pred = regressor_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aac3a0b5-5714-4d0e-b98b-a4c3a8f725c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(regressor_model, open(\"save_models/regressor_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "168db6ea-89e1-4d63-999a-c88ef725ec16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Classification ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d35187c2-1182-4d1a-8b92-86f5637f70af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "# or from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_dtype_1, y_c, test_size=0.2, random_state=42)\n",
    "run_name=\"lightgbm_Classification_dtype1\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    lgbm_best_params = {\n",
    "    \"n_estimators\": 800,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 45,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.5,\n",
    "    \"is_unbalance\": True,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1}\n",
    "\n",
    "    model = LGBMClassifier(**lgbm_best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    logging(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"LGBMclassifier\",signature= infer_signature(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d335e470-f930-4507-888f-de2446588a0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "# or from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_dtype_2, y_c, test_size=0.2, random_state=42)\n",
    "run_name=\"lightgbm_Classification_dtype2\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    lgbm_best_params = {\n",
    "    \"n_estimators\": 800,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 45,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.5,\n",
    "    \"is_unbalance\": True,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1}\n",
    "\n",
    "    model = LGBMClassifier(**lgbm_best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    logging(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"LGBMclassifier\",signature= infer_signature(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "734a9c34-c418-445e-8a9c-c41f1ce4cc32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(x_dtype_1, y_c, rebalance=True)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "run_name = \"xgboost_classifier_dtype1\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    classes = np.unique(y_train)\n",
    "    class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", \n",
    "    classes=classes, \n",
    "    y=y_train)\n",
    "    class_weights_dict = dict(zip(classes, class_weights))\n",
    "    print(\"üìä Class Weights:\", class_weights_dict)\n",
    "\n",
    "# 2Ô∏è‚É£ Define model parameters\n",
    "    xgb_multiclass_params = {\n",
    "        \"n_estimators\": 800,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 7,\n",
    "        \"min_child_weight\": 3,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"gamma\": 0.1,\n",
    "        \"reg_alpha\": 0.1,\n",
    "        \"reg_lambda\": 1.0,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"objective\": \"multi:softprob\",    # üëà multiclass objective\n",
    "        \"num_class\": len(classes),        # üëà number of classes\n",
    "        \"eval_metric\": \"mlogloss\",        # üëà better metric for multiclass\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1}\n",
    "\n",
    "    # 3Ô∏è‚É£ Initialize model\n",
    "    model = XGBClassifier(**xgb_multiclass_params)\n",
    "\n",
    "    # 4Ô∏è‚É£ Pass sample weights to handle imbalance\n",
    "    sample_weights = np.array([class_weights_dict[label] for label in y_train])\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    logging(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"XGBclassifier\", signature= infer_signature(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05efabf8-86d1-41c4-9301-3f35d16cf63e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ea3bbe5-4d88-4adf-bfbf-60f45aedd0fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "new_x_dtype1=x_dtype_1.copy()\n",
    "new_x_dtype1[\"max_monthly_emi\"]=y_r\n",
    "X_train, X_test, y_train, y_test = data_split(new_x_dtype1, y_c, rebalance=True)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "run_name = \"xgboost_classifier_dtype1\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    classes = np.unique(y_train)\n",
    "    class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", \n",
    "    classes=classes, \n",
    "    y=y_train)\n",
    "    class_weights_dict = dict(zip(classes, class_weights))\n",
    "    print(\"üìä Class Weights:\", class_weights_dict)\n",
    "\n",
    "# 2Ô∏è‚É£ Define model parameters\n",
    "    xgb_multiclass_params = {\n",
    "        \"n_estimators\": 800,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 7,\n",
    "        \"min_child_weight\": 3,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"gamma\": 0.1,\n",
    "        \"reg_alpha\": 0.1,\n",
    "        \"reg_lambda\": 1.0,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"objective\": \"multi:softprob\",    # üëà multiclass objective\n",
    "        \"num_class\": len(classes),        # üëà number of classes\n",
    "        \"eval_metric\": \"mlogloss\",        # üëà better metric for multiclass\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1}\n",
    "\n",
    "    # 3Ô∏è‚É£ Initialize model\n",
    "    model = XGBClassifier(**xgb_multiclass_params)\n",
    "\n",
    "    # 4Ô∏è‚É£ Pass sample weights to handle imbalance\n",
    "    sample_weights = np.array([class_weights_dict[label] for label in y_train])\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    logging(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"XGBclassifier\", signature= infer_signature(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdf2eed7-65c5-4214-bc89-207474a294b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "new_x_dtype2=x_dtype_2.copy()\n",
    "new_x_dtype2[\"max_monthly_emi\"]=y_r\n",
    "X_train, X_test, y_train, y_test = data_split(new_x_dtype2, y_c, rebalance=True)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "run_name = \"xgboost_classifier_dtype2\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    classes = np.unique(y_train)\n",
    "    class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", \n",
    "    classes=classes, \n",
    "    y=y_train)\n",
    "    class_weights_dict = dict(zip(classes, class_weights))\n",
    "    print(\"üìä Class Weights:\", class_weights_dict)\n",
    "\n",
    "# 2Ô∏è‚É£ Define model parameters\n",
    "    xgb_multiclass_params = {\n",
    "        \"n_estimators\": 800,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 7,\n",
    "        \"min_child_weight\": 3,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"gamma\": 0.1,\n",
    "        \"reg_alpha\": 0.1,\n",
    "        \"reg_lambda\": 1.0,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"objective\": \"multi:softprob\",    # üëà multiclass objective\n",
    "        \"num_class\": len(classes),        # üëà number of classes\n",
    "        \"eval_metric\": \"mlogloss\",        # üëà better metric for multiclass\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1}\n",
    "\n",
    "    # 3Ô∏è‚É£ Initialize model\n",
    "    model = XGBClassifier(**xgb_multiclass_params)\n",
    "\n",
    "    # 4Ô∏è‚É£ Pass sample weights to handle imbalance\n",
    "    sample_weights = np.array([class_weights_dict[label] for label in y_train])\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    logging(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"XGBclassifier\", signature= infer_signature(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aefa49eb-d424-4d1c-9e51-6826ab8ba12e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "new_x_dtype1=x_dtype_1.copy()\n",
    "new_x_dtype1[\"max_monthly_emi\"]=y_r\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_x_dtype1, y_c, test_size=0.2, random_state=42)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "run_name = \"xgboost_classifier_dtype1\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    classes = np.unique(y_train)\n",
    "    class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", \n",
    "    classes=classes, \n",
    "    y=y_train)\n",
    "    class_weights_dict = dict(zip(classes, class_weights))\n",
    "    print(\"üìä Class Weights:\", class_weights_dict)\n",
    "\n",
    "# 2Ô∏è‚É£ Define model parameters\n",
    "    xgb_multiclass_params = {\n",
    "        \"n_estimators\": 800,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 7,\n",
    "        \"min_child_weight\": 3,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"gamma\": 0.1,\n",
    "        \"reg_alpha\": 0.1,\n",
    "        \"reg_lambda\": 1.0,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"objective\": \"multi:softprob\",    # üëà multiclass objective\n",
    "        \"num_class\": len(classes),        # üëà number of classes\n",
    "        \"eval_metric\": \"mlogloss\",        # üëà better metric for multiclass\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1}\n",
    "\n",
    "    # 3Ô∏è‚É£ Initialize model\n",
    "    model = XGBClassifier(**xgb_multiclass_params)\n",
    "\n",
    "    # 4Ô∏è‚É£ Pass sample weights to handle imbalance\n",
    "    sample_weights = np.array([class_weights_dict[label] for label in y_train])\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    logging(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"XGBclassifier\", signature= infer_signature(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a26c3cac-4646-459a-b7c4-f9c57fa3477a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "# or from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "new_x_dtype2=x_dtype_2.copy()\n",
    "new_x_dtype2[\"max_monthly_emi\"]=y_r\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(new_x_dtype2, y_c, rebalance=True)\n",
    "run_name=\"lightgbm_Classification_dtype2\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    lgbm_best_params = {\n",
    "    \"n_estimators\": 800,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 45,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.5,\n",
    "    \"is_unbalance\": True,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1}\n",
    "    mlflow.log_params(lgbm_best_params)\n",
    "    model = LGBMClassifier(**lgbm_best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    logging(y_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"LGBMclassifier\",signature= infer_signature(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "398acc98-c9be-43e3-ab0b-c54e1036b473",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb55fcec-f3c1-4665-a98c-29a69cc42537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_x_dtype2=x_dtype_2.copy()\n",
    "new_x_dtype2[\"max_monthly_emi\"]=y_r\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(new_x_dtype2, y_c, rebalance=True)\n",
    "\n",
    "lgbm_best_params = {\n",
    "    \"n_estimators\": 800,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 45,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.5,\n",
    "    \"is_unbalance\": True,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1}\n",
    "classifier_model = LGBMClassifier(**lgbm_best_params)\n",
    "classifier_model.fit(X_train, y_train)\n",
    "y_pred = classifier_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97c1ca39-c9b3-40f4-8945-84bff67dcf0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(classifier_model, open('save_models/classifier_model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Final_models_training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
